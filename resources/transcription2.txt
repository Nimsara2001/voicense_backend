All right, let's get started.
Please try to have a seat if you can find a seat and let's get the show on the road.
So welcome everyone to CS221, this is artificial intelligence and if you're new to Stanford,
welcome to Stanford.
So first let's do some introductions.
So I'm Percy, I'm going to be one of your instructors teaching this class with Dorsa
over there.
So if Dorsa wants to say hi, stand up.
Hi, I'm Dorsa.
I'll be co-teaching this class.
I'm Percy.
I work on robotics and robot interaction.
Super excited about this class.
Great, so we're going to be trading off throughout the quarter and we also have a wonderful teaching
team.
So these are your CAs.
So if all the CAs could stand up and I'll give you each person an opportunity to say
three words about what you're interested in.
So let's start with the head TA.
Hello, my name is Dorsa.
I'm a PhD student and I'm interested in natural language processing.
Yay.
Hi, my name is Dorsa.
I'm a second year master's student.
I'm interested in machine learning and data mining.
Hi, I'm Dorsa.
I'm a second year master's student.
I'm interested in machine learning and data mining.
Hi, I'm Dorsa.
I'm a second year master's student.
I'm interested in machine learning and data mining.
Hi, I'm Dorsa.
I'm a second year master's student.
I'm interested in machine learning and data mining.
Hi, I'm Dorsa.
I'm a second year master's student.
I'm interested in machine learning and data mining.
Hi, I'm Dorsa.
I'm a second year master's student.
I'm interested in machine learning and data mining.
Hi, I'm Dorsa.
I'm a second year master's student.
I'm interested in machine learning and data mining.
Hi, I'm Dorsa.
I'm a second year master's student.
I'm interested in machine learning and data mining.
Hi, I'm Dorsa.
I'm a second year master's student.
I'm interested in machine learning and data mining.
Hi, I'm Dorsa.
I'm a second year master's student.
I'm interested in machine learning and data mining.
Hi, I'm Dorsa.
I'm a second year master's student.
I'm interested in machine learning and data mining.
Hi, I'm Dorsa.
I'm a second year master's student.
I'm interested in machine learning and data mining.
Hi, I'm Dorsa.
I'm a second year master's student.
I'm interested in machine learning and data mining.
Hi, I'm Dorsa.
I'm a second year master's student.
I'm interested in machine learning and data mining.
Hi, I'm Dorsa.
I'm a second year master's student.
I'm interested in machine learning and data mining.
Hi, I'm Dorsa.
I'm a second year master's student.
I'm interested in machine learning and data mining.
Hi, I'm Dorsa.
I'm a second year master's student.
I'm interested in machine learning and data mining.
Hi, I'm Dorsa.
I'm a second year master's student.
I'm interested in machine learning and data mining.
Hi, I'm Dorsa.
I'm interested in machine learning and data mining.
Hi, I'm Dorsa.
Hi, I'm Dorsa.
I'm interested in machine learning and data mining.
Hi, I'm Dorsa.
I'm interested in machine learning and data mining.
Hi, I'm Dorsa.
I'm interested in machine learning and data mining.
Hi, I'm Dorsa.
I'm interested in machine learning and data mining.
Hi, I'm Dorsa.
I'm interested in machine learning and data mining.
Hi, I'm Dorsa.
I'm interested in machine learning and data mining.
Hi, I'm Dorsa.
I'm interested in machine learning and data mining.
Hi, I'm Dorsa.
I'm interested in machine learning and data mining.
Hi, I'm Dorsa.
I'm interested in machine learning and data mining.
Hi, I'm Dorsa.
I'm interested in machine learning and data mining.
Hi, I'm Dorsa.
Hi, I'm Dorsa.
I'm interested in machine learning.
Hi, I'm Dorsa.
Hi, I'm Dorsa.
Hi, I'm Dorsa.
Hi, I'm Dorsa.
I'm interested in machine learning
In the back.
Well, while they are on the slide.
Okay, so as you can see we kind of have a very diverse team.
And so when you're thinking about kind of final projects later in the quarter, you can
tap into the Santa incredible resource.
Um, so three quick announcements.
Um, so there's going to be a section every week which will
cover both kind of a review topics and also advanced, uh, topics.
So this th- Thursday there's gonna be an overview.
Um, if you're kind of rusty on Python or rusty on probability,
come to this and we'll get you up to speed.
Um, homework- the first homework is out.
It's posted on the website.
It's due next Tuesday at 11 PM.
So remember the time that matters.
Um, all submissions will be done on Gradescope.
There's gonna be a Gradescope co- code that will be posted on Piazza.
So look out for that, um, later.
Okay. So now let's- let's begin.
So when I first started teaching this class, uh, seven years ago,
I used to have to motivate why AI was important and why,
if you study it, you'll have a lot of impact in the world.
But I feel like I don't really need to do this.
Now it's kind of inescapable that you pick up the news in the morning,
you hear something about, you know, AI.
And indeed we've seen a lot of success stories, right?
Uh, AIs that can play Jeopardy or play Go,
Dota 2, even Poker,
all these kind of games at superhuman level performance.
It can also, you know,
read documents and answer questions,
do speech recognition, uh,
face recognition, um, even kind of medical imaging.
And all these tasks are, uh,
you read about how successful these, uh, technologies have been.
Um, and then if you take a look at outside the kind of the technical circles,
there's a lot of people, um,
apologizing, um, and trying to ask what is going on with AI.
And you, you hear about these kind of very, uh,
broad claims of how transformative AI will be, um,
to the future of work and, um, the society and so on.
And even some kind of bordering on, uh,
pretty, you know, catastrophic consequences.
So what's gonna happen in the future?
No one knows. Um, but it is fair to say that AI will be transformative.
Um, but how do we get here?
And to do that, I want to take a step back to the summer of 1956.
So the place was Dartmouth College.
John McCarthy, who was then at MIT,
and then, uh, after that,
he founded the Stanford AI Lab, um,
organized a workshop at Dartmouth College with, um,
o- some of the best and brightest minds of the time,
Marvin Minsky, uh, Claude Shannon, and so on.
And they had this not so modest goal of trying to think that
every aspect of learning or any feature of intelligence can be
precisely captured so that a machine can be just, uh, simulated.
So they were after the- the big question of how do you kind of solve, um, AI.
So now they didn't make that much progress over the- the summer,
but a lot of programs and interesting artifacts came about from that time.
Um, there were programs that could play checkers or prove, uh,
theorems and sometimes even better than what, um,
you know, the human proof would look like.
Um, and there was a lot of optimism.
People are really, really excited.
And you can see these quotes by all these excited people who
proclaimed that AI would be solved in a matter of years.
But we know that didn't really happen.
And there's this kind of folklore example.
Uh, people were trying to do machine translation.
So you take an English sentence like,
the spirit is willing but the flesh is weak.
You translate into Russian,
which is what, um,
the choice language by the US government at that time.
And you could, uh,
translate back into English and this is what you get.
The vodka is good but the meat is rotten.
Um, the government didn't think that was too funny.
So they cut off the funding and, um,
it became the first AI winter.
Um, so there's a period where, you know,
AI research was not very active and was not well- very well funded.
Um, so what went wrong here?
Um, these are really smart people, right?
Um, they just got a little maybe a little ahead of themselves.
So two problems.
One is that the compute was simply not there, right?
It was millions or even billions of order of magnitude
compared less than what we have, uh, right now.
And also the problem is the way they formulate them,
intrinsically relying on kind of exponential search,
which, um, no matter how much compute you have,
you're never going to, you know, uh, win that race.
Um, they also have a limited, you know, information.
And this is maybe a kind of a more subtle point that if I gave you
infinite compute and I asked you to translate,
I don't think you would be able to figure it out because it's not a computation problem.
You just need to learn the language and you need to
experience all the subtleties of language to be able to, you know, translate.
But on the other hand,
AI wasn't solved but a lot of interesting,
um, contributions to computer science came out of it.
Lisp was just- had a lot of ideas that, um,
underlay many- many of the high-level program languages we have, garbage collection,
um, time-sharing, allowing, uh,
multiple people to use the same- one computer at the same time,
which is something that, uh,
we kind of take for granted.
And also this paradigm of separating what you want to compute,
which is modeling and how you do it,
which is inference, which we'll get to a little bit later.
Okay. So, um, people forget quickly.
And, um, in the 17th and 80s,
there was a renewed generation of people getting excited about AI again.
Um, and this time,
it was all about knowledge, right?
Knowledge is power.
And, um, there were a lot of expert systems which are created.
And the idea is that if you could encode experts' knowledge about the world,
then you could do kind of amazing things.
And at the time, the knowledge was encoded in generally a set of rules.
Um, and there were a lot of programs that was written.
And you notice that the- the scope is much narrower now.
The goal isn't to solve all of AI but to really focus on some choice,
some problems like diagnosing the diseases or converting
customers' order parts into parts and a customer orders into parts.
And, uh, this was the first time that AI,
I think, really had a real impact on industries.
So, uh, people were actually able to make useful,
you know, products out of this.
And knowledge did actually play a key ingredient in curbing
this, you know, exponential growth that people were worried about.
But of course, um, it didn't last long.
Um, knowledge as deterministic rules was simply not rich enough to
capture all the kind of nuances of the world.
It required a lot of manual effort to maintain.
And, um, again, um,
a pattern of over-promising and under-liverings that seems to plague,
um, AI people, um,
led to the collapse and- of the field and the kind of second AI winter.
Um, okay, so that's not the end of the story either.
But actually, it's not kind of really the beginning either.
Um, so I'm going to step back further in time to 1943.
So what happened in 1943?
So there was, um,
a neuroscientist, McCullough, and a logician,
Pitts, who were wondering and marveling at how the human brain is able to do all these kind of complicated things.
And they want to kind of formulate a theory about how this could all happen.
So they developed a theory of, um,
artificial neural networks.
Um, and this is kind of, you can think about the root as of,
you know, deep learning in some sense.
Um, and what was interesting is that they looked at,
um, neurons and logic,
which are two things that you might not kind of necessarily associate with each other,
and showed how they were kind of connected mathematically.
And a lot of the early work in this era were- of- around
artificial neural networks was about studying them kind of from a mathematical, uh, perspective.
Um, because at that time,
the computer wasn't there, you couldn't really run any kind of training,
any models or, um- and then in 1969,
something interesting happened.
So there's this book by Minsky and Papert called Perceptrons.
And this book did a lot of mathematical analysis,
and it also showed that linear models,
one of the results of- of many was showing that linear classifiers couldn't solve the XOR problem.
Um, the problem is- another way to think about the problem is basically given two inputs,
can you tell whether they're the- the same or not, or different?
And, um, so it's kind of not a- shouldn't be a hard problem,
but linear classifiers can do it.
And for some reason,
which I don't quite understand,
it killed off neural nets research,
even though they said nothing about if you had a deeper network, what it could do.
Um, but it's often cited that this book, uh,
swung things from people who were interested in neural networks to the field of
AI being very symbolic and logic-driven.
Um, but there was always this kind of minority group,
um, who were really invested and believed in,
um, the power of neural networks,
and I think that was just kind of a matter of time.
So in the 80s, there was a renewed interest.
Um, people kind of discovered or rediscovered the backpropagation algorithm,
which allowed, uh, kind of a- for a generic algorithm that could train these multilayer neural networks,
because single layer, remember,
was insufficient to do a lot of things.
Um, and then one of the kind of the early success stories,
uh, Zianna Kuhn in- in 1989,
uh, applied a convolutional neural network and was able to recognize hand-digit- written digits,
and this actually got, you know,
deployed by the USPS and was reading kind of ZIP codes.
Um, so this was, you know, great.
Um, but it wasn't until this decade that the, um,
this area of neural networks really kind of took off,
um, under the moniker deep learning, um,
and, you know, AlexNet in 2012 was kind of
a huge transformation, um,
where they show gains on the kind of ImageNet benchmark and- and overnight,
transformed the computer vision community, um,
AlphaGo, as, you know,
many of you know, and many kind of other,
um, and there were kind of the rest of this history.
Okay. So- so there's these kind of two intellectual traditions.
Um, you know, the name AI has always been associated with a kind of John McCarthy logical tradition.
That's kind of where it started.
But, um, as you can see that there's also kind of this,
uh, neuroscience-inspired tradition of AI.
And the two were kind of really have some deep philosophical differences and
over the decades fought with each other kind of quite a bit.
But I want to pause for a moment and really think about,
maybe they're actually kind of deeper connections here.
Remember McCollum-Pitts, they were studying artificial neural networks,
but the connection was to logic, right?
So from even in the very beginning,
there is kind of this synergy that, you know,
some- some people can kind of often overlook.
And if you take a look at AlphaGo,
which if you think about the game of Go or many games,
it's a mathematically- you can write down the rules of,
uh, Go in logic in just a few lines.
So it's a mathematically well-defined logical- logic puzzle in some sense.
But somehow the- the power of neural networks allows you to
develop these models that actually play Go really, really well.
So this is kind of one of the deep mysteries that has kind of a- I think is
a kind of open- open- standing challenge, you know, in AI.
Um, as with any story,
it's not a full picture.
And I want to point out on this slide that AI has drawn from a lot of different,
you know, fields. Many of the techniques that we're gonna look at, for example,
maximum likelihood came from, you know,
statistics or games came from kind of economics, optimizations, gradient descent,
came from, um, was, you know,
in the 50s completely unrelated to AI,
but these techniques kind of developed in a different context.
And so AI is kind of like,
you know, it's kind of like a New York City.
It's- it's like a melting pot where a lot of the- these techniques get kind of
unified and apply to kind of interesting problems.
And that's what makes it, I think,
really interesting because of the- the new avenues that are
opened up by kind of unique combinations of, um, existing techniques.
Okay. So- so that was a really,
really brief, uh, history of, you know, where- how we got here.
Um, now I want to pause for a moment and think about,
you know, what is- what is the goal?
What- what are AI people trying to do?
And again, this- this is kind of- there's two ways to think about this,
which- and sometimes the conflation of these causes a lot of confusion.
Um, so I'd like to think about it as AI as agents and AI as tools.
So the first view asks the kind of assignment question of,
how can we create or recreate intelligence?
And the second one asks, you know,
how can we use technology to kind of benefit, you know, society?
And these two are obviously very related and they have,
um, a lot of shared technical,
um, um, overlap,
but, you know, philosophically, they're kind of different.
So let me kind of explain this a little bit.
So the idea with AI agents is- and this is- I- I think a lot of what,
um, um, gets associated with AI, um,
and especially, you know, with science fiction,
that kind of portrayal certainly kind of, um,
encourages this kind of view where you're human- we're human beings.
And what you do is you look in the mirror and you say,
wow, that must- that's a really smart person.
And you think, okay, how- how- what- what- what can
humans do that is, you know, so, you know, amazing?
Well, they can, um,
they can see and they can perceive the world, recognize objects.
Um, they can grasp cups and drink water and not spill it.
Um, they can communicate using language as I'm doing to you right now.
Um, we know facts about the world,
declarative knowledge such as what's the capital of France,
and procedural knowledge like how to ride a bike.
We can reason with this knowledge and maybe ride a bike to the capital of France.
And then really importantly,
we're not born with all of this, right?
We're born with basically nothing,
none of these capabilities,
but we're born with the capacity and potential to acquire these over time through experience.
And learning it seems to be kind of this critical ingredient,
which drives a lot of the success in AI today,
but also with, um, you know,
human intelligence it's clear that learning plays such a central role
in getting us to the level that we are operating at.
So each of these areas has kind of spawned entire subfields,
and people in it are kind of wondering about how you can, um,
make artificial systems that have the language or the motor or
the visual perceptual capabilities that, you know, humans have.
But are we there yet?
Um, and I would- I would like to think that we are,
uh, very far.
So if you look at the way that machines are having successful,
it's all with a narrow set of tasks and,
you know, millions or billions of examples,
and you just crunch a lot of computation,
and you can really kind of, uh,
optimize, um, every- any tasks you're gonna come- come up with.
Whereas humans operate in a very different regime.
They don't necessarily do any, you know,
one thing well, but they are- have such a kind of diverse set of, you know,
experiences, can solve the diverse set of tasks,
and learn from each individual task from very few examples.
And still, it's a kind of a grand challenge in- from,
uh, you know, Congress perspective,
how you can build systems with this level of capability in- that humans have.
So the other view is, you know,
AI tools. Basically, you would say, okay, well, you know,
it's kind of cool to think about how we can,
uh, you know, recreate intelligence.
But, you know, we don't really care about making more,
um, things like humans.
We already have a way of, you know,
doing that, that's called, you know, babies.
Um, so what instead we really like to do is not making something that's like a human,
but making systems that help humans because, you know,
after all, we're- we're humans.
I guess it's a little bit selfish,
but, um, we're in charge right now.
Um, and- and a lot of these- this view,
and a lot of the success stories in AI are really different
from the things that you expect, you know,
this, uh, this humanoid robot to come into your house and be able to do.
For example, this is a project from, uh,
Stefano Ehrman's group, um,
there's a lot of poverty in the world,
and, um, part of it is just kind of understanding what- what's- what's going on.
And they had this idea of using, uh,
computer vision on satellite imagery to predict things like,
you know, uh, GDP.
Um, so this is obviously not a task that, you know,
the- our ancestors in Africa were,
like, you know, getting really good at.
Um, but nonetheless, it uses convolutional neural networks,
which is a technique that was inspired by,
um, you know, the brain.
And so that's- that's kind of interesting.
Um, you can also have another application for saving energy by trying to figure out when to cool data centers.
Um, as AI is, uh,
being deployed in more kind of mission-critical situations such as self-driving cars or authentication,
there are- there are a few new issues that come up.
So for example, there are this phenomenon called adversarial examples, um,
where you can take, um,
these cool looking glasses,
you can put them on your face,
and you can fool the computer, um,
uh, save our, uh,
face recognition system to think that you're actually, you know, someone else.
Um, or you can post these, uh,
stickers on stop signs and get this,
uh, save our system to think that it's,
uh, um, a speed limit sign.
So there's obvious- there's- clearly these are,
you know, big problems if we think about the widespread deployment of AI.
Um, there's also, uh,
less catastrophically but also pretty, um, you know,
uh, upsetting, which is, uh,
biases that you- many of you probably have read in the news about.
Um, so for example,
if you take Malay,
which is a language that, uh,
doesn't distinguish, um,
in the writing form between he and she,
and you stick into Google Translate, um,
you see that she works as a nurse,
but he works as a programmer,
which is encoding certain, uh,
societal biases, um,
in the actual models.
And one kind of important point I wanna bring up is that,
you know, how is machine learning and AI kind of working today?
Well, it's, um, you know,
society exists,
society is generating a lot of data,
we're training on this data,
and kind of trying to fit the data and trying to mimic what it's doing,
and then using predictions on it.
What could possibly go wrong, right?
Um, and so, so certainly people,
a lot of people have been thinking about, um,
how these biases are kind of creeping up as an open,
active area of research.
Um, something a little bit more kind of sensitive is,
you know, asking, well,
these systems are being deployed to all these,
all these people, whether they kind of wanted or- wanted or not.
Um, and this, this actually touches on,
you know, people's, uh, you know, livelihoods.
It actually impacts people's lives in a serious way.
Um, so North Point was a company that built, uh,
a software called Compass that tries to predict how risky,
um, criminal risk score,
how is someone, how risky someone is essentially.
Um, and ProPublica,
this organization realized, whoa, whoa, whoa.
You have the system that, uh,
given the individual didn't re-offend,
is actually, um, more,
twice as likely to classify blacks as incorrectly as,
you know, non-blacks.
So this is, uh, seems pretty problematic.
And the North Point comes back and says, actually,
you know, I think we, I think we're being fair.
Um, so given a risk score of 7,
uh, we were fair because 60% of whites re-offended and 60% of blacks re-offended.
Um, the, the point here is that there's,
there's, there's actually no, um,
solution to this in some sense, sadly.
Um, so people have formulated different notions of fairness and equality between,
um, how you predict a court on different kind of, um, groups.
But, um, all you can have different, uh,
notions of fairness and which all seem reasonable from first principles,
but mathematically they can be,
um, incompatible with each other.
So this is, again,
an open area of research where we're trying to figure out as a society,
how, um, to deal with this given that machine learning
might be used in these kind of critical situations.
Okay. So summary so far, um,
there's the agent's view.
Um, we're trying to really kind of dream and think about how do you get these capabilities,
like learning from very few examples that humans have
into, you know, machines and maybe opening up a kind of,
uh, a different set of technical capabilities.
But at the same time,
uh, we really need to be thinking about how these AI systems are affecting the real world.
And things like security and biases and fairness all kind of show up.
It's also interesting to note that, you know,
a lot of the challenges in deployment of AI system don't really have
necessarily to do with, um, you know, humans at all.
I mean, humans are incredibly biased,
but that doesn't mean we want to build systems kind of in our,
um, that mimic humans and kind of inherit all the,
kind of the flaws that humans have.
Okay. Any questions about this?
Maybe pause for a moment.
So let's go on.
Um, so what I want to do next is give an overview of the different topics, um, in the course.
Um, and the way to think about all of this is that,
um, in AI, we're trying to solve really complex problems.
The real world is really complicated.
And- but at the end of the day,
we want to produce some software or maybe some hardware that actually runs and does stuff, right?
And so there's a very considerable gap between these things.
And so how do you even approach something like self-driving cars or,
um, you know, diagnosing diseases?
You probably shouldn't just like go sit down at a terminal and start typing,
because then, um, there- there's no- kind of no overarching structure.
So what this class is going to do is to give you one example of a structure,
which will hopefully help you approach hard problems and think about how to solve them in a kind of more principled way.
Um, so this is a paradigm that I call the,
um, modeling inference and learning paradigm.
Um, so the idea here is that there's three pillars,
which I'll explain in a bit.
And, uh, we can focus on each one of these things kind of in turn.
So the first pillar is modeling.
So what is modeling?
The modeling is taking the real world,
which is really complicated,
and building a model out of it.
So what is a model? Model is a simplification.
That is mathematically precise so that you can,
you know, do something with it, uh, on a computer.
Um, one of the things that's necessary is that modeling,
um, necessary has to simplify things and,
you know, throw away information.
Um, so one of the kind of, uh,
the, you know, the art is to figure out what information to pay attention to and what information to keep.
Um, so this is going to be important.
For example, when you work on your final projects and you have a real world problem,
you need to figure out, um,
you can't have everything and you have to figure out judiciously how to,
uh, manage your, you know, resources.
So here's an example. If you want to, for example,
build a- a system that can find,
uh, the best way to get from point A to point B in a graph- in a city,
you can formulate the model as a graph where those are points in the city and edges represent
a- ability to go between these points with some sort of cost, um, on the edges.
Okay. So now, once you have your model,
you can do, uh, inference.
And what inference means is asking questions about your model.
So here's a model. You can ask, for example,
how- what is the shortest path from, um,
this point to, uh, this point, right?
And that's because now your model land is a mathematically well-defined, uh, problem.
Now you can- it's within the realm of, uh, you know,
devi- developing algorithms to, you know, solve that problem.
And most of inference is being able to do these computations, um, really efficiently.
And finally, learning addresses the problem,
where does this model come from?
So in any kind of realistic setting,
um, the model might have a lot of parameters.
Maybe it has, you know, millions of parameters.
And how do you s- if it- if it wants to be faithful to the, you know, real world,
but how do you get all this, uh, information there?
Um, manually encoding this information turns out not to be a good idea.
This is, um, in some sense what, um,
AI from the 80s was trying to do.
Um, so the learning paradigm is as follows.
What we're gonna do is specify a model without parameters.
Think about it as a skeleton.
So in this case, we have a graph,
but we don't know what the edge weights are.
Um, and now we have some data.
So maybe we have data of the form people try to go from x to y,
and they took 10 minutes or an hour or so on.
Um, and then from this data,
we can learn to fit the parameters of the model.
We can assign, um,
costs to the edges that kind of are representative of what the data is telling us.
Okay? So now in this way,
we can write down a model without parameters,
feed the data, apply a generic learning algorithm,
and get a model with parameters.
And now we can go back and do, um,
inference and ask questions, you know, about this.
Okay. So this is kind of the- the- the paradigm.
And I want to really emphasize that, you know,
learning is not, as I presented,
is really not about any one particular algorithm,
like nearest neighbors or neural networks.
It's really a kind of a philosophy of how you go about approaching problems,
by defining a model and then not having to specify all the details,
but filling them in later.
Okay. So here is the, um, plan for the course.
We're gonna go from low-level intelligence to high-level intelligence.
Um, and this is the intelligence of,
um, of the- of the models that we're gonna be talking about.
So first, we're gonna talk about machine learning.
And like I've kind of alluded to earlier,
machine learning is going to be such a kind of
a important building block of- that can be applied to any of the models that we develop.
Um, so the central tenet in machine learning is you have data and you go to model.
It's main, uh,
driver of a lot of success- successes in AI because it allows you to,
um, in software engineering terms,
move the complexity from code to data.
Rather having, you know,
a million lines of code which is unmanageable,
you have a lot of data,
which is, um, collected in kind of a more natural way and
a smaller amount of code that can operate on this data.
And this paradigm has really been, um, iteratively powerful.
One thing to think about in terms of machine learning is that it- it is- requires a leap of faith, right?
So you can go through the mechanics of, you know,
downloading some machine learning code and you train a model.
But fundamentally, it's about generalization, right?
You have your data, you fit a model,
but you don't care about how it performs on that data,
you care about how it performs on new experiences.
And that leap of faith is something that's, um,
I think gives machine learning its power,
but it's also a little bit, um,
at first glance perhaps magical.
Um, it turns out you can actually formalize a lot of this using,
um, you know, probability theory and statistics,
but that's kind of a topic for another time.
Okay. So after we talk about machine learning,
we're going to go back and talk about the- the simplest of models, right?
So a reflex model is this.
So here's a quiz.
Okay. What is this animal?
Okay. Zebra. How did you get it so fast?
Well, it's kind of reflex, right?
Your human visual system is so good,
um, at- at doing these things without thinking.
Um, and so reflex models are these,
um, are models which just require a fixed set of computations.
So examples like our linear classifiers, deep neural networks,
um, and most of these models are the ones that people in machine learning, um, use.
Models is almost synonymous with, um,
reflex, um, in, you know, machine learning.
An important thing that there's no feed for it.
It's just like you get your input, bam, bam, bam,
and here's your output.
Okay. So that's- that's great because it- it's fast.
But there's some problems that require a little bit more than that, right?
So for example, here's another problem.
Okay, quick. Why to move? Where should you go?
Okay. There's- there's probably like a few of you who are like chess geniuses.
Um, but for the rest of us,
um, I have no idea.
I don't even know, wait, who's moving again?
Um, so- so in these kind of situations,
we need something perhaps a little bit more powerful than a reflex.
We need agents that can kind of plan and think, um, ahead.
So the idea behind state-based models is that we model the world as a set of
states which capture any given situation like a- a position in a- in a game.
And actions that take us between states,
which correspond to things that, um,
you can do in the- in this game.
Um, so a lot of game applications fall into this category, robotics,
motion planning, navigation.
Um, also some things that are- might not be,
uh, you might think of, um,
planning such as gen- you know, generation,
um, in natural language or generating an image.
Um, you know, are- can be cast in this way as well.
So there's three types of state-based models,
each of which we'll cover in, um, you know, weeks of time.
So search problems are the classic,
uh, you control everything,
so you're just trying to fi- find the optimal path.
There are cases where there's randomness.
For example, if you're trying to go from point A to point B,
maybe there's traffic that you don't,
you know, don't know about or, um,
in a game there might be, uh,
dice that are- die which are road.
And, uh, there's a third category which are adversarial games,
which is cases where you're playing an opponent who's actively trying to destroy you.
So what are you gonna do about it?
Um, so one of the games that we're gonna,
uh, be talking about, uh,
when we talk about games is Pac-Man.
And one of the assignments is,
um, actually building, um,
a Pac-Man agent such as this.
So, um, while you're looking at this,
think about how- what are the states and what are the actions and how would you go about,
you know, devising a strategy for Pac-Man to eat all the dots and avoid all the ghosts?
So that's something, uh,
to maybe look forward to.
There's also gonna be a competition,
so we'll see, um, who ends up on top.
Okay. So state-based models,
um, are very powerful.
They allow you to kind of have foresight.
Um, but some problems are not really most naturally cast as state-based models.
For example, you know, how many of you have played Sudoku or have played it before?
So the goal of Sudoku is to fill in
these, uh, um, blanks with numbers so that,
um, every row, column,
and three by three sublock has a religious one through nine,
so it's a bunch of constraints.
Um, and there's no kind of sense in which you have to do in a certain order, right?
Whereas the- the- the order in how you move in- in chess or something is,
you know, pretty important.
Um, so- so these type of problems, uh,
are- are captured by these, uh,
variable-based models where you kind of think about a solution to the problem as
an assignment to the individual variables under some constraints.
So constraint satisfaction problems,
we'll spend a week on that.
Um, these are hard constraints.
For example, two people can't be- a person can't be in two places at once, for example.
Um, there's also Bayesian networks which we'll talk about which are
variable-based models with, uh, soft dependencies.
For example, if you're trying to track,
um, you know, a car over time,
these are the positions of the car,
these variables represent the position of the cars,
and these, uh, E's represent the- the sensor readings of the position- of the car at that particular position.
And inference looks like trying to figure out where the- the car was given all this kind of noisy sensor reading.
So that's also gonna be another assignment that you're gonna deal with.
Okay. So finally, um,
now we get to high-level- what's the- what is high-level intelligence here?
Um, and I put logic here,
um, for a reason that you'll see clear.
Yeah, is there a question?
The Sudoku example, can you explain why it's not a state-based model?
Yeah. So the question is, why is not the- why is the Sudoku problem not a space- based model?
Um, you can actually formulate this as a state-based model,
um, by just thinking about the sequence of, uh, assignments.
But it turns out that, um,
you can formulate it in a kind of more natural way as a variable-based model,
which allows you to, uh,
take advantage of some kind of more efficient algorithm to solve it, right?
It's- it- think about these models as kind of different,
um, analogy is like a programming language.
So yes, you could write everything in, you know,
C++ but sometimes writing in, you know,
Python or- or SQL for some things might be more, um, might be easier. Yeah.
How would you categorize a state-based problem where you have
both an adversarial element and an element of randomness?
Yeah. So the question is, how do you categorize state-based models where there's both randomness and an adversary?
Um, we're also gonna talk about those as well.
Um, and those would be av- I would classify them as adversarial,
but there's also a random component that you have to deal with.
Yeah, question.
Um, are we just trying to like,
go from discrete things to like,
continuous spaces? It feels like we have like,
problems that are- that are qualified will be our like- and then,
and then the farther right we get,
the more we need like to come up with.
Yeah. So the question is about whether, uh,
some of these are more continuous and some of them are discrete.
Um, I don't necessarily think of, uh,
so a lot of the reflex models actually can work in continuous state spaces,
for example, images.
Um, actually it's- it's almost a little bit of the opposite where,
um, the logic-based models are in some sense more,
you know, discrete, but you can also have continuous elements,
you know, in there, um, as well.
Um, so in this class,
we're mostly gonna focus on kind of discrete objects
because they're just going to be simpler to work with.
Okay. So what is this logic?
So the motivation here is that suppose you, um,
wanted a little companion who, um,
you could boss around and, um,
and help- or help you do things,
let's say that's a better way to say it.
Um, so you'd like to be able to say,
okay, you know, tell us some information, um,
and you know, then later you want to be able to ask some questions
and have the system be able to reply to you.
Um, so, um, you know,
how- how would you go about doing this?
One way you could think about is building
a system that you can actually talk to using natural language.
Okay. So I'm actually gonna show you a- a little demo,
um, which, uh, is gonna come up in the last assignment on logic.
Um, and well, let's see what you think of it.
Um, okay. So this is going to be a system that is,
um, based on logic that I'm going to,
um, tell the system a bunch of things,
and I'm gonna ask some questions.
So, um, I want you all to follow along and see if you can,
you know, play the role of the agent.
Okay. So I'm gonna teach you a few things,
like, um, Alice is a student.
Okay. So it says, I learned something.
Now, let's- let's quiz.
Um, is- is Alice a student?
Okay. Good. So that worked.
Um, is Bob a student?
Should answer you. I don't know who's Bob.
Um, okay. So now let's do, um,
students are, um, people.
Um, Alice is not a person.
I don't buy that. Okay. So, um, okay.
It's- you know, it's doing some reasoning, right?
It's using logic. It's not, um, just, um, okay.
So now let's do, um,
Alice is from, you know, Phoenix.
Uh, Phoenix is a hot city.
I know because I live there.
Um, cities are places.
And if it is snowing,
uh, it is, um, then it is cold.
Okay. Got it.
So, um, is it snowing?
I don't know. Um, so how about this?
Okay. So if, um, a person is from a hot place and it is cold,
then she is not happy.
Okay. True. Right.
Um, yes. Those of you who have spent all your life in California,
would maybe appreciate this.
But, um, okay.
So is it snowing now?
How many of you say, yeah, it's snowing?
How many say no? Don't know.
Okay.
I just wanted to throw a little bit to the US.
Oh. Uh, too late.
Um, how about if I say Alice is, uh, happy?
Okay. So is it snowing now?
No, it should be no. Okay.
So you, you guys were able to do this.
Okay. So this is kind of an example of an interaction,
which, um, if you think about it,
it has, it's very,
very different from what you would see kind of in a typical,
um, you know, ML system where you have to show it,
you know, millions of examples of one particular thing,
and then it can do kind of one task.
This is much more of a very open-ended set of, um,
um, I want to say that the experiences are super rich,
but they're definitely diverse.
I teach, um, I just give one statement.
I say it once, and then all of a sudden it has all the ramifications
and, uh, kind of consequences of that built in,
and it kind of understands in a kind of deeper level.
Of course, this is, uh, based on, you know, logic systems.
Um, so it is brittle,
but this is kind of just a proof of concepts to give you a taste of what I mean when I say logic.
So, uh, so these systems need to be able to digest
these heterogeneous information and reason deeply with that information,
and we'll see kind of how,
um, logic systems can do that.
Okay. So that completes the tour of the topics of this class.
Um, now I want to spend a little bit of time on course logistics.
Uh, so, um, I want to- all of the details here are online.
So I'm not going to be complete in my coverage,
um, but I just want to give you a general sense of what's going on here.
Okay. So what are we trying to do in this course?
Um, so, uh, prerequisites,
um, there's programming, um,
discrete math, and, uh, probability.
So you need to be able to code, you need to be able to,
um, do some math and, uh,
some kind of basic proofs, right?
So these are the classes that are, um,
you know, required or at least recommended,
uh, that you- or if you have some equivalent experience,
that's, you know, fine too.
Um, and what we- what should you hope to get out of this course, right?
So one had the course is meant to be giving you a set of tools.
Using the modeling inference learning paradigm,
it gives you a set of tools and a way of thinking about problems that hopefully will
be really useful for you when you go out in the world and try to solve real-world problems.
Um, and also about- as a side product,
I also want all of you to be more proficient at, you know,
math and programming because those are kind of
the core elements that are- enable you to do kind of interesting, you know, things in AI.
So a lot of AI, you know,
you read about it is very flashy,
but really the foundations are still, um,
just, you know, math and programming in some sense.
Okay. So the coursework is homeworks exam in a project.
That's what you have to do.
Um, homeworks, there's eight homeworks.
Each homework is a mix of write- written and programming problems
centered on a particular application covering one particular type of model essentially.
Um, like I mentioned before,
there's a competition for extra credit.
There's also some extra credit problems in the- in the homeworks.
Um, and when you submit code,
um, we're gonna run- we have an autograder that runs.
It's gonna run on all the test cases,
but you get a feedback on a subset.
So you can, um, it's like, you know,
in machine learning, you have a train set and you have a test set.
So don't train on your test set.
Okay. So, um, the exam is,
uh, testing your ability to use the knowledge that you learned to solve new problems, right?
So there's, um, and I- I think it's worth taking a look at the exam
because it kind of surprises people every- the exam is a little bit different
than the types of problems that you see on,
uh, on the homework and they're kind of more problem, you know, solving.
So the exam isn't gonna be like a multiple choice like, okay,
you know, um, you know,
when was, uh, um, you know,
perceptron publishers, you know, something like that.
It's gonna be, here's a real life problem.
How do you model it and how do you come up with a, you know, solution?
Um, they're all gonna be written,
it's closed book except for you have a one page of notes.
And this is a great opportunity to actually, um,
review all the material and actually learn the- the content of the class.
Um, so the project I think is a really good opportunity to take all the things
that we've been talking about in the class and, um,
try to find something you really care about and try to apply it.
Um, work in groups of three and I really recommend finding a group early.
Um, and it's- I emphasize it's your responsibility to find,
you know, a good group, right?
Um, don't come to us later,
like one week before the project is lined and say,
oh, you know, my group members,
they, um, they ditch me or something.
Really try to- try to nail this down.
Use Piazza to- or your other,
um, social networks to find a good group.
So throughout the quarter,
there's gonna be these milestones for the project.
So, um, to prevent you guys from procrastinating until the very end.
Um, so there's gonna be a proposal where you try and brainstorm some ideas,
progress report, a poster session,
which is actually a whole week before the final report is due.
Um, and the project is very open.
So this can be, um,
really liberating but also might be a little bit, um, daunting.
Um, we will hopefully give you a lot of structure in terms of saying,
okay, how do you define your task?
How do you implement different, um,
baselines and oracles, which I'll explain later.
How do you evaluate?
How do you, um, analyze what you've done?
Um, and each of you will- each project group will be assigned a CA mentor,
um, to help you, uh,
through the process and you're always welcome to come to my office hours or
Dorsa's or any of the CA's to get additional, um,
help either brainstorming or figuring out what the next, uh, step is.
Um, some policies, uh,
all assignments will be submitted on Gradescope.
Um, there's seven total late days.
You can use at most two per assignment.
After that, there's no credit.
Um, uh, we're gonna use Piazza for all communication.
So don't email us directly,
leave a post on Piazza.
If, uh, I encourage you to make it public if it's,
um, it's not sensitive but if it's,
you know, personal then obviously make it private.
Um, and try to help each other.
We'll actually award some extra credit for students who help answer,
um, you know, other students' questions.
So all of these shows on the course.
Okay. So one last thing and it's really important and that's the honor code.
Okay. So especially if you're, um,
you know, you've probably heard this if you've been at Stanford,
if you haven't, then I want to really kind of make this clear.
So I encourage you all to kind of collaborate, discuss together.
But when you- when it comes to actually the homeworks,
you have to write up your homework and,
you know, code it independently.
So you shouldn't be looking at someone's write-up.
Um, you shouldn't be looking at their code.
Um, and you definitely shouldn't be copying code off of GitHub.
Um, um, that's hopefully should be, you know,
obvious and maybe less obvious you should not,
please do not post your homework assignments on GitHub.
I know you're probably proud of the fact your Pac-Man agent is doing really well,
but, um, please don't post on GitHub
because then that's going to be an honor code violation.
Um, when debugging, um,
with- if you're working together,
it's fine to- as long as it's kind of looking at input-output behavior.
So you can say to your partner,
hey, I put in this, um,
input to my test case, I'm getting like three, what are you getting?
So that's fine, but you can't,
um, remember, don't look at each other's code.
Um, and as you enforce this,
we're going to be running MOS which is a software program that looks for
code duplication, um, to- to make sure that,
uh, the rules are being followed.
And, you know, changing one variable name is,
or you- you'll be so- anyway, enough said.
Just don't- don't- don't do it.
Okay. Any questions about this?
I want to make sure this is important or about any of the logistics. Yeah.
Does the GitHub thing apply to the final project?
The final project, uh, you can put on GitHub.
Yeah.
Uh, do you have private GitHub repos, uh, like,
as a group or can you do a solo project?
Yeah. Private GitHub repos, uh, is fine.
Yeah. Question in the back.
Is it necessary to have a group or can you do a solo project?
Uh, the question is, can you- can you do a solo project?
You can do a solo project,
you can do a project with two people,
you can do a project with three.
I would encourage you to try to work in,
uh, groups of three because you'll be able to do more as a group.
And there's definitely, uh, you know,
it- it's not like if you do solo project,
we'll be expecting like one-third of the work.
So. Okay. Anything else? All right.
Okay. So in the final, um, section,
I want to actually delve into some technical details.
Um, and one thing we're gonna focus on right now is,
um, the kind of inference and learning components of- of this course.
So I'm gonna talk about how you can approach these through the lens of,
you know, optimization.
So this is going to be, um,
it might be a review for some of you,
but hopefully it's gonna be a- a good,
um, um, you know,
way to get everyone on the same page.
Okay. So what is optimization?
There's still two flavors of optimization that we care about.
There's, uh, discrete optimization where you're trying to find the best,
uh, discrete object.
For example, you're trying to find the best, uh, path,
or some- the path P that minimizes the cost of that path.
Um, we're going to talk about one algorithmic tool,
um, based on dynamic programming,
which is a very powerful way of solving these,
um, complex optimization problems.
Um, and the key, you know,
property here is that the set of path is huge and you can't just,
uh, try all of them and compute their cost and choose the best one.
So you're gonna have to do something clever.
The second brand of optimization is continuous optimization.
And formally, this is just finding the best, uh,
vector of real numbers that satisfies or minimizes some objective function.
So a typical place this shows up is in learning where you
define, uh, objective function like the training error,
and you're trying to find a weight vector W.
So this notation just means it's a list of numbers,
D numbers that minimizes the training error.
And we're gonna show that gradient descent is, uh, uh,
easy and a ver- a surprisingly effective way of solving these,
um, continuous optimization problems.
Okay. So to introduce these two ideas,
I'm gonna look at two, um,
problems and try to kind of work through them.
So this might be also a good, um,
you know, way to think about how you might go approach,
uh, you know, homework problems.
And I'm trying to kind of talk through this, um, in a bit more detail.
Okay. So the first problem is,
um, you know, computing at its distance.
Um, and, you know,
this might not look, you know,
like an AI problem but a lot of, uh,
AI problems have this as kind of a, you know,
building block if you want to do some sort of matching between,
um, you know, two words or two, um, biological sequences.
So the input is you're given two strings.
Um, I'm gonna start writing over here on the board to work this out.
So you're given two strings, um, S and T. Um,
so for example, um,
a cat and, um, the cats.
Okay. So these are two strings and you want to find
the minimum number of edits that is needed to take transform S into T.
And by edits, I mean you can, uh,
insert, um, a character like you can insert a S,
you can delete characters,
I can delete this A,
and you can substitute one character for another so you can replace this A with a T.
Okay. Um, so here's some examples.
What's the edit instance of cat and cat?
It's zero, you don't have to do anything.
Cat and dog is three.
Cat and add is one, you insert the A or insert the C. Um,
cat and cats is one, um,
and a cat and the cats is, uh, four.
Okay. So the challenge here is that there are,
uh, quite a different number of ways to insert and delete, right?
So if you have a string of- that's very long,
there's just way too many things to like just try out all of them.
Um, okay. So then how do we- how do we go about,
um, coming up with a solution?
So any ideas? Yeah.
Can we simplify the output in terms of saying that a substitution is considered- or a deletion can be considered a substitution for diversifying like an empty character?
Yeah, yeah. So let's try to simplify the- the problem a bit and building up on what you- um, what was said.
So, um, one thing to note is that,
okay, we're- so the general principle,
let me just write the general principle,
um, is to, you know,
reduce the- the problem to a simpler problem because that you can hopefully solve.
It's easier to solve and then you can maybe keep on doing that until you get something that's trivial.
Okay. So there's maybe two observations we can make.
One is that, well,
we're technically saying we can,
um, you know, insert into S, right?
But if we insert into S,
it makes the problem kind of larger in some sense, right?
I mean, that's not- that's not good.
That's not reducing the problem.
But- but whenever we insert into S,
um, we probably want to insert things which are in T. We want to,
like, cancel something out, right?
So we wouldn't insert a K there for any reason.
We probably want to insert a S in which case,
you know, S matches that and then we've reduced that problem, right?
So we can actually think about, you know,
inserting into S- to S as equivalent to kind of deleting from,
um, from T. Okay.
Does that make sense? All right.
So another observation we can make is that,
um, you know, we can start inserting anywhere.
We can start inserting here and then jump over here and do this.
But this just introduces a lot of,
um, you know, ways of doing it which all kind of result in the same answer.
So why don't we just start more systematically at one end,
and then just proceed and try to chisel off the problem,
um, kind of, let's say from the end.
Okay. So, um, start at the end.
Okay. So, so now we have this,
um, problem.
I'm gonna draw a problem in a little box here.
Um, so let's start at the end. Yeah, question.
What was the reasoning that we used to reach that principle, start at the end?
Oh, the question is,
why are we starting at the end?
As opposed- well, um,
the idea is that if you start at the end,
then you have kind of a more systematic and consistent way of,
you know, reducing the problem.
So you don't have to think about all the permutations of where I can,
you know, delete and substitute.
Why is it more systematic to go from the right to the left than from the left to the right?
We can also do left to right.
So the end or the start, um, is both fine.
This is just- I just picked the end. Yeah.
How do we know starting at one end can give us the optimal strategy?
Yeah. The question is, how do we know that starting,
um, at one end can give you the optimal strategy?
Um, so, you know,
if you wanted to prove this more rigorously,
there's some work,
but, um, I'll just try to give you a, you know, intuitive answer.
Um, suppose you didn't start at the end and you just made a sequence of steps,
like I insert here,
I delete here, and then I went over here,
and, um, did all those operations to S.
I could have equivalently also just sorted those by,
you know, where it was happening,
and then just proceeded from one end to the other,
and I would arrive at the exact same answer.
So without loss of generality, I can start that.
Any other questions?
Okay. So, yeah.
Instead of doing this, wouldn't the more vulnerable approach be trying to,
uh, recognize some patterns instead of, uh,
doing this, I mean between the two, uh, strings SMT,
like some sort of, some sort of pattern that have that input in both of the SMT strings?
Yeah. The question is, maybe you can recognize some patterns.
Wow. Well, it's like, oh, cat.
That's, uh, that's- maybe those should be lined up.
Um, I guess these examples are chosen so that these patterns exist,
but we want to solve the problem for cases where,
um, the pattern might not be obvious.
It could be- we want to work for- it to work for all strings.
Maybe there is no pattern and we still would want to kind of efficient algorithm to do it. Yeah.
Just like use dynamic programming.
Like we go one by one,
there is always like six or two steps.
Either we're doing, um,
substitution or, um,
otherwise it's like the same character or we have to insert.
Yeah.
Um, and then we keep going and you just like remember each like two,
two strings that we have at one point so that if we calculated that,
we don't have to do it again.
Yeah, yeah.
And that's it. Yeah.
Yeah. Yeah. Great idea.
Let's do dynamic programming.
Um, so that's what I'm kind of trying to build up from, uh, build up to.
Okay. So, um, so if you look at this,
so dynamic programming is a kind of general technique that
essentially allows you to express this more complicated problem instead of a simpler problem.
So let's start with this problem.
If we start at the end,
um, if the two match then,
well, we can just immediately,
uh, you know, delete these two and it's- it's gonna be the same, right?
So we can get- we can get some free rides there.
Okay. But when they differ,
um, now we have many options.
So what we- what could we do?
Well, we could, um, um, you know, substitute.
Okay. We can change the t to an s.
So what does that leave us with?
So I can do, uh, cat- um,
t is the- the cat, the- okay.
So I can substitute, um, okay.
Um, what else can I do?
Someone say something I can do.
So I can insert, um, insert where?
Into- so I can insert an s, right?
But that's the same as, you know,
by one deleting from t.
So by- you can basically also just delete the s.
Um, so this is our cat and I deleted this s from t. Okay.
So this is, um, let's call it, uh, you know,
um, I guess let's call this insertion.
It's technically insertion.
And then finally, what can I do?
I can also remove t. So a, k, c,
a, t, the cat.
Okay. So this is delete.
And right now, you're probably looking at this like, well,
obviously, you know, you- you should do this one.
But in general, it's hard to tell, right?
I just gave you some arbitrary strains.
Uh, you know, who knows what the right answer is.
Um, so in general, how do you pick?
Yeah.
The second one, the p is supposed to be the cat.
You mean this one?
So here I inserted an s, right?
But then because there's two s's here,
I just cancel them out.
And so you can think about this as really deleting
from, um, yeah.
Yeah. Yeah. Yeah. So I'm- I'm- because of this,
I'm kind of trying to reframe the problem a little bit.
Okay. So which one should I choose? Yeah.
What about the substitution the other way?
Um, the substitution the other way, meaning change.
Sorry, there's too many s's and two's here.
Which is a bit of a- unfortunate.
And then replace the last n with a t.
Oh, you could-
How do you eliminate that? How do you do that?
Um, that's- you can think about that as kind of equivalent.
So if you identify two letters that you want to make the same,
then, uh, I mean, you could- you can
replace the one to be the other or the other to be that.
I mean, officially we've been kind of training it as we're only editing s,
which is the reason that it's not econometric.
Okay. So which one of these?
Door A, door B, or door- door C? Yeah.
Would you look for some of the s's and b's at every step,
and then you'd look for the middle one because there's a cat in both of them?
Yeah. So you could try to look inside,
but, um, but remember,
these are- might be really complicated.
So we want to kind of a simple mechanized procedure to tell.
What about the next letter?
The next letter.
Yeah, like, you can-
Um, yeah, let's- let's pretend these are- you- you can't see inside them.
Okay.
Okay.
Can we keep going with each of the different cases?
Yeah. Okay. So let's keep on going.
So I'm not gonna draw everything,
but you can also try to break this down into maybe there's three actions here and three actions here, right?
Um, and at the end of the day,
you hopefully have a problem that's simple enough that,
um, where s equals c or something, then you're done.
Um, but then, you know,
how- how do I- how do I know?
Suppose I've solved this.
Suppose someone just told you, okay,
I know this, um, cost,
I know this cost, I know this cost.
What- what should you do?
Yeah, you should take the minimum, right?
Like remember, we want to minimize the edit distance.
So, um, there's three things you can do.
Each of them has some cost of doing that action,
which is, you know, one,
every edit is the same cost.
And then there's a cost of, you know,
continuing to do whatever you're doing.
And so we're just gonna take the minimum of it up. Yeah.
So if the person turns right or left,
how do we know that that's the actual amount of movement that we have to take?
Yeah. So, um, I was trying to argue that,
um, with- if you're going to right or left,
it's, uh, without lots of generality.
Because if you went left to right or in some other order,
you can also replay the edits.
Um.
Yeah, I can't wonder if there's one letter that you need when you're searching on like the top left,
and like the top string.
But if you went from left to left,
it looks like as if they're all shifted over by one or- no, I think that's it.
Yeah.
Oh, that will work.
Okay.
Yeah, I think it'll work.
Um, okay.
So- so let's, um,
try to code this up and see if we can make this program work.
Okay. So, um, I'm gonna do edit distance.
Can everyone see this?
Okay. So, um,
I'm gonna define a function that takes two strings.
And then I'm going to, um, define a recurrence.
So recurrences are, uh,
is I guess one word I haven't really used.
But this is really the way you should kind of think about, uh,
dynamic programs and this idea of taking complex problems and breaking it down.
It's gonna show up in, you know, search problems, um,
MDPs and, you know, games.
So I guess it's something that you should really be comfortable with.
So let's, um, define a recurrence, uh, as follows.
Um, so remember at any point in time,
I have, uh, let's say a subproblem.
And since I'm going right to left,
I'm only considering the first, um,
M letters of S and the first letter- N letters of T, okay?
So recurrence is going to return the minimum edit distance between two things,
the first M letters of S and the first N letters of T.
Um, I'm gonna post this online so you guys don't have to,
like, copy- try to copy this.
Um, okay.
So, um, okay.
Suppose I'm gonna- I'm gonna define this function.
If I have this function, what should I return?
Recurse of- so M is an integer, right?
So N is an integer,
so I'm gonna return the length of M and the length of M, okay?
So that's kind of, uh, the initial state.
Okay. Um, all right.
So now I need to fill out this function.
Okay. So let's- let's, um,
consider a bunch of cases.
So here's some easy cases.
Suppose that, um, M is 0, right?
So I have comparing an empty string with something that has N letters.
So what should the cost of that be?
I heard something wrong the last- it should be N.
And symmetrically, if N is 0,
then result should be M. Um,
and then if- now we come to the kind of initial case that we consider,
which is the N- actually match.
So if, um, S, um,
the last letter of M,
you know, this is, uh,
zero-based indexing, um,
so that's why there's a minus 1.
So if this matches, then what should I do?
So now I reduce this to a sub-problem, right?
So I re- have M minus 1, M minus 1.
Okay. And now comes the fun case,
which we, uh, looked at.
So there's, um, in this case,
the last letter doesn't match,
so I'm gonna have to do some sort of edit.
I can't just let it- yeah.
Uh, would it be worth doing a full SDE compare or S through M and S through N compare?
Uh, would it be worth doing a full SDE compare?
Rather than waiting until, um,
like, doing like a last letter match?
Yeah. There- there's probably a way you can make this more efficient.
I'm just gonna try to get the basic thing in there.
Okay. So substitution, okay?
So what's the cost of a substitution?
I pay one to do the substitution,
but- and in- as a reward,
I get to, um, reduce the problem to M minus 1 and M minus 1, right?
So I lop off a letter from S and I lop off a letter from T.
Um, so what else can I do?
So I can, um, you know,
delete- so that also costs 1.
And when I delete, I delete from S,
and then N, so this remains the same.
And then now you can think about the insertion,
um, is N minus 1, right?
Because remember insertion into S is deletion from T,
that's why this is N minus 1.
Okay. And then the result is just going to be a minimum of all these things.
Okay. Return result. Okay.
So just, uh, and then how do I call this function?
Um, a cat, the cats.
So let me print out the answer.
Um, let's see if it works.
Okay, print out 4. Therefore, I conclude it works now.
Um, you- I mean, if you were doing this,
uh, you would probably want to test this some more,
but in the interest of time, I'll kind of move on.
So let me just kind of refresh.
Okay. So I'm computing this at a distance between two strings,
and we're going to define a recurrence that works on subproblems,
where the subproblem is the first M letters of S and the first N letters of T.
Um, and the reason I'm using integers instead of,
um, strings is to avoid like string copying,
um, implementation detail, but it doesn't really matter.
Um, so base cases.
So you want to reduce your problem to a case where it's- it's trivial to solve.
Um, and then we have the last letter matches,
and then we have a letter that doesn't match and you have to pay some sort of cost.
I don't know which action to take,
so I'm going to take them, you know, minimum of all of them.
And then I call it by just calling, you know, recurrence.
Okay. So this is great, right?
So now I have a working thing.
Um, let's try another test case.
So I'm going to make this, um, so if I do times 10,
this, um, basically, uh,
replicates this string 10 times.
So it's, uh, it's a long string, longer string.
Okay. So now I'm going to run it.
And maybe I shouldn't wait for this.
Um, there is a base case.
I- I think it works,
but it's- it's, um, what- what's wrong with this code?
Um, yes, it's very slow.
Why is it slow?
I think you guys are reading it in a way that it's slow.
Yeah, right. So- so I'm recursing.
Every point recurses three times,
so you kind of get this exponential, you know, blow up.
Um, so there's kind of a- how do you solve this problem?
You can memo- I think I heard the word memoize,
which is another way to kind of think about memoize plus,
um, I guess recurrent is- is dynamic programming, I guess.
Um, so I'm going to show you kind of this,
um, way to do it,
which is pretty un- uninvasive.
Um, and generally I recommend people, well,
get- get the slow version working and then try to make it faster.
Don't try to be, you know, too, uh, slick at once.
Okay. So I'm going to make this cache, right?
And I'm going to say if MN is in the cache,
then I'm going to return whatever is in the cache.
So cache is just a dictionary mapping, um,
the key which is, um,
identification of the problem I'm interested in solving,
and the result which is the answer that I computed.
So if I already computed it,
I don't need to compute it again, just return it.
And then at the end,
if I have to compute it,
then, um, I have to put this in the cache.
Okay. So three lines or four lines, I guess.
Yeah.
What if you want to cache out the recursive function?
Yeah, that's a great point.
This should be outside of the recursive function.
Yeah. Glad you guys are paying attention.
Um, otherwise, yeah,
it would do basically nothing. Any other mistakes? Yeah.
Um, there are some function decorators that like implement memoizing for you.
In this class, are you okay if we use that,
or would you rather us like make our own in this case?
Um, you can use the decor- you can be fancy if you want.
Okay.
Yeah. But- but I think this is,
you know, pretty transparent and easy for learning purposes.
Okay. So let's run this.
So now it runs instantaneously as opposed to,
I- I actually don't know how long it would have taken otherwise.
Okay. And sanity check for d is probably the right answer,
because there's four with the original answer and multiply by 10.
Okay. Any other questions about this?
So this is an example of, you know,
kind of basic, uh, dynamic programming,
which are, uh, you solve a problem trying to formulate it as a recurrence of
a complicated problem in terms of smaller problems.
Um, and like I said before,
this is going to kind of show up,
um, um, over and over again in this class.
Yeah.
Yeah. The question is, why does this reduce,
uh, redundancy? Is that right?
Um, so maybe I can do it kind of pictorially.
Um, if you think about- let's say you have a- a problem here, right?
And this gets, um, you know,
reduced to, um- I'm just making kind of
arbitrary, um, diagram here.
So this problem gets reduced to these two,
and this problem gets reduced to these two, um, and- and so on.
Um, right?
So if you think about- if you didn't have memoization,
you would just be paying for the number of paths.
Every path is the kind of you have to compute from scratch.
Whereas, um, if you do memoization,
you pay in the number of nodes here,
which a lot of this is shared.
Like here, um, you know,
once you compute this, no matter if you're coming from here or here,
you're kind of using the same value.
Okay. So let's- let's move on.
So the second problem, um,
we're gonna talk about is,
uh, has to do with continuous optimization.
And the motivating question here is,
how do you do, um,
regression, which is the kind of a bread and butter of,
um, you know, machine learning here.
So- so here we go.
Um, regression.
Okay. So imagine, um, you get some points.
Okay. So I give you a point,
um, which is, you know,
two, four, um,
and then I give you another point,
let's say, um, four, two.
And so these are data points.
You want to, let's say,
predict, um, um,
housing price from, you know,
square footage or something like that.
You want to predict health score from,
um, you know, blood pressure and some other things.
So this is pretty common in machine learning.
And the question is, how do you fit,
um, you know, a line?
I'm gonna kind of consider the case where your line has to go through the origin,
just for simplicity. Um, so you might want to,
like, find, you know, a fit.
I mean, two points is maybe kind of a little bit degenerate,
but, um, that's the simple example we're gonna, you know, work with.
In general, you have lots of points and you want to fit the line that best,
kind of, uh, is close to the points.
Okay. So, um, how do you do this?
Um, so there's a principle called least squares,
which says, well,
if you give me a line,
which is given in this case by a slope w,
um, I'm going to tell you how bad this is.
And badness is measured by looking at all the training points,
and looking at these, uh, distances, right?
So here I have, um, you know,
this particular, uh,
a particular, let's say point, you know,
xi, if I hit it with a w,
then I get basically the, um, you know,
the y-intercept, um, here.
Not the y-intercept, but the- like the y value here.
That's my prediction.
The real value was, um,
you know, yi, which is, you know, up here.
And so if I look at the difference,
I want that difference to be 0, right?
So in least squares,
I square this and I say,
I want this to be as small as possible, right?
Now, this is only for one point,
so I'm going to look at all the points.
Let's suppose I have n points, um,
and that's a function that I'm gonna call f of w,
which basically says for a given weight vector,
which is a slope, um,
give you a number that characterizes how bad of a fit, um, this is.
Where 0 means that I fit everything perfectly,
and large numbers mean that I fit this poorly.
Okay? All right.
So- so that's, you know, regression.
So how do I solve, uh, regression problem?
So how do I optimize this?
Can you do this in your head?
So if I actually have these two points, which should w be?
Okay. It doesn't matter. We'll- we'll compute it.
So how do we go about doing this?
So one principle, um,
which is maybe another general takeaway is abstract away the details, right?
Um, this is also true with the dynamic program,
but sometimes, you know, you get- if you're too close to board and you're looking at,
oh man, these points are here and I need to fit this line, you know,
how do I do that? Um, um,
you- you kind of get kind of a little bit stuck.
But why don't we think about this f as say some function.
I don't- I don't really care what it is.
And let's plot this function, okay?
So now this is a different plot now.
This is, uh, the weight and this is f of w.
Um, always label your axes.
Um, and let's say this function looks like, uh, this, okay?
So which means that for this slope,
I pay, you know, this amount.
For this slope, I pay this amount and- and so on.
And what do I want to do?
I want to minimize f of w,
which means I want to find, um,
the w which, um,
has the least value of f of w, right? Question?
Okay. So you take the derivative.
So what does the derivative give you?
It tells you where to move, right?
So if you look over here, um,
so you can't- in general,
you might not be able to get there directly.
In this actually particular case,
you can because you can solve in closed form,
but I'm gonna try to be more general.
Um, so if you start here,
this- this derivative tells you, well,
the function is decreasing if you move to the right.
So then you should move to the right.
Whereas over here, if you end up over here,
the derivative says, uh,
the function is decreasing if you move to the left.
So you should move to the left, right?
So, um, what I'm gonna introduce is this algorithm called gradient descent.
It's a very simple algorithm.
It basically says, start with some place,
and then compute the derivative,
and just follow your nose, right?
If the derivative says it's negative,
then just go this way,
and now you're at a new point,
and you compute the derivative again,
you descend, and now you compute it again,
and then maybe you, uh,
compute the derivative and it says, keep on going this way,
maybe you overshoot, and then you come back,
and then, you know, hopefully, uh,
you'll end up kind of at the minimum, okay?
So, uh, let's try to see what this looks like in code.
So gradient descent is,
you know, one of the simplest algorithms,
but it really underlies essentially all the algorithms
that you people use in machine learning.
Um, so let's do points.
We have, uh, two points here.
Um, and I'm gonna define, um, some functions, okay?
So f of w. So what is this function?
So I'm going to sum over all the different, um, you know,
and basically at this point,
it's converting math into Python.
So I'm gonna look at all the, um, points.
So for every x, y, um,
what the model predicts is w times x minus y, um,
and if I square that,
that's going to be the,
the error that I get on that point.
And then if I sum over all of these errors,
then I get my objective function, okay?
So what do you do with, uh, an array of, uh,
yeah, so you can put an array here if you want,
but it doesn't- it's actually fine.
Um, okay, so now I need to compute the derivative.
So how do you compute the derivative?
So if your calculus is a little bit rusty,
you might want to brush up on it.
Um, so what's the derivative?
Remember we're taking a derivative with respect to w, right?
There's a lot of symbols here.
Always remember what you're taking a derivative with respect to.
Okay, the derivative of the sum is the sum of the derivative.
So now I need to take the derivative of this, right?
And what's the derivative of this?
Well, something squared, um,
you bring the 2 down here and now you multiply by the derivative of this.
And what's the derivative of this?
Should be x, right?
Because this is a- y,
this is a constant and w derivative- w times x with respect to w is x.
Okay, so that's it. Okay, so now let's do gradient descent.
Um, let's initialize with w equals 0.
And then I'm going to just, um,
you know, just iterate 100 times.
Normally you would set some sort of stopping condition,
but, um, let's just keep it simple for now.
Okay, so for every moment,
I'm going to- I have a w. I can compute the value of the function,
and I also take the gradient of the derivative.
Gradient just means derivative in higher d- dimensions,
which we'll want later.
Um, okay. And then what do I do?
I take, uh, w and I,
um, subtract the- the gradient.
Okay? So remember-
I'll be able to find the gradient.
Okay, I'll be out of- yeah.
So, uh, I take the gradient.
Remember, I want to have the gradient.
Uh, gradient tells me where the function is increasing,
so I want to move in the opposite direction.
Um, and eta is just going to be this,
uh, step size to, um,
keep things under control.
We'll talk more about it next time.
Okay, so now I want to do,
uh, per now what's going on here.
So iteration, um,
print out the function and, um, t value.
Okay? All right.
So let's compute the gradient.
And, um, so you can see that the iteration,
we first start out with w equals 0,
then it moves to 0.3, um,
and then it moves to 0.7999999,
and then it looks like it's converging to 0.8.
And meanwhile, the function value is going down from 20 to,
uh, 7.2, which happens to be the optimal answer.
So the correct answer here is 0.8.
Okay, so that's it.
Next time we're gonna keep,
uh, we're gonna start on the machine learning lecture.
